{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from pandas import read_csv, DataFrame\n",
    "from itertools import product, chain, starmap, combinations, combinations_with_replacement\n",
    "from time import time\n",
    "# import fast\n",
    "time0 = time()\n",
    "\n",
    "k = 2\n",
    "divisions = 1\n",
    "range_ = 0.00\n",
    "seed = 123\n",
    "\n",
    "# 1. Function definitions\n",
    "\n",
    "def discretize(seq, divisions=divisions, range_=range_, seed=seed):\n",
    "    '''\n",
    "    >>> discretize([3, 4, 1, 8, 13, 8], divisions=4, range_=0, seed=123) = array([1, 1, 0, 2, 3, 2])\n",
    "    where\n",
    "    ranks = [2., 3., 1., 4.5, 6., 4.5]\n",
    "    tresholds = [1.5,  3.,  4.5]\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    ranks = rankdata(seq, method='ordinal') # method='ordinal'/'average' ?\n",
    "\n",
    "    random_blocks = np.cumsum(range_ * (2 * np.random.random(divisions + 1) - 1) + np.ones(divisions + 1))\n",
    "    tresholds = random_blocks[:-1] / random_blocks[-1] * len(seq)\n",
    "    \n",
    "    discrete_seq = np.zeros(len(seq), dtype='float64')\n",
    "    for treshold in tresholds:\n",
    "        discrete_seq[ranks > treshold] += 1\n",
    "    return discrete_seq\n",
    "\n",
    "discretize_vec = np.vectorize(discretize, signature='(n)->(n)', excluded=['divisions', 'range_', 'seed'])\n",
    "\n",
    "# 2. Read the data\n",
    "\n",
    "file = \"my_df_2.csv\"\n",
    "data = []\n",
    "with open(file) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',',\n",
    "                        quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "        \n",
    "data = np.array(data, dtype='float64').T[:-1]\n",
    "data[:-1] = discretize_vec(data[:-1])\n",
    "data = data.astype('int64')\n",
    "\n",
    "labels, counts = np.unique(data[-1], return_counts=True)\n",
    "n_classes = len(labels)\n",
    "\n",
    "xi = 1e-5\n",
    "pseudo_counts = xi * counts / np.min(counts)\n",
    "\n",
    "\n",
    "dim0, dim1 = data[:-1].shape\n",
    "\n",
    "# 3. More function definitions\n",
    "\n",
    "def tuple_generator(k=k, dim0=dim0):\n",
    "    '''\n",
    "    Python-generator.\n",
    "    E.g. output for k=2:\n",
    "    {0,1}, {0,2}, ..., {0, dim0-1}, {1,2}, ..., {1,dim0-1}, ..., {dim0-2, dim0-1}\n",
    "    Go with combinations_with_replacement() to include diagonal tuples like {0, 0}\n",
    "    '''        \n",
    "    return combinations(range(dim0), k)    \n",
    "\n",
    "def neg_H(p):\n",
    "    return p * np.log2(p)\n",
    "\n",
    "def neg_H_cond(matrix):\n",
    "    return np.sum(neg_H(matrix)) - np.sum(neg_H(np.sum(matrix, axis=-1)))\n",
    "\n",
    "def slow_work(indeces):\n",
    "    '''\n",
    "    indeces -> tuple\n",
    "    Work-function.\n",
    "    Output: tuple of Information Gains implicitly corresponding to the indeces\n",
    "    '''\n",
    "    # contingency-matrix: begin with pseudo-counts\n",
    "    contingency_m = np.empty([divisions + 1] * k + [len(labels)], dtype='float64')\n",
    "    for label, pseudo_count in enumerate(pseudo_counts):\n",
    "        contingency_m[..., label] = pseudo_count\n",
    "    \n",
    "    # contingency-matrix: normal counts\n",
    "    for c_index in data[list(indeces) + [-1]].T:\n",
    "        contingency_m[tuple(c_index)] += 1\n",
    "    \n",
    "    results = []\n",
    "    for i in range(len(indeces)):\n",
    "        result = neg_H_cond(contingency_m) - neg_H_cond(np.sum(contingency_m, axis=i))\n",
    "        results.append(result)\n",
    "    return tuple(results)\n",
    "\n",
    "\n",
    "def record(tuple_, IGs, records):\n",
    "    for column, IG in zip(tuple_, IGs):\n",
    "        if column not in records or IG > records[column][0]:\n",
    "            records[column] = (IG, tuple_)\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "for tuple_ in tuple_generator():\n",
    "    IGs = slow_work(tuple_)\n",
    "    #IGs = fast.work_2(dim1, divisions, data[tuple_[0]], data[tuple_[1]], n_classes, pseudo_counts, data[-1])\n",
    "    #IGs = fast.work_3(dim1, divisions, data[tuple_[0]], data[tuple_[1]], data[tuple_[2]], n_classes, pseudo_counts, data[-1])\n",
    "    record(tuple_, IGs, final_results)\n",
    "\n",
    "# result\n",
    "print(\"Finished in\", time() - time0, \"sec.\")\n",
    "result = DataFrame(final_results).T.rename(columns={0: 'IG_max', 1: 'tuple'})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

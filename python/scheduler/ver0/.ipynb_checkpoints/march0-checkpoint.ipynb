{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the `cpp` functions used previousy in `february0.ipynb` but with the `Matrix` class in place of bare arrays for the contingency matrices. The class is defined and implemented in `matrix_class.h` and, in all likelyhood, it could use a review, refinement and optimization. One function, `work_3_old`, uses the old approach without the new class, so that one can easily check that the final results didn't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fast.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile fast.cpp\n",
    "/*\n",
    "<%\n",
    "cfg['compiler_args'] = ['-std=c++11', '-fopenmp']\n",
    "cfg['linker_args'] = ['-fopenmp']\n",
    "setup_pybind11(cfg)\n",
    "%>\n",
    "*/\n",
    "\n",
    "#include <math.h>\n",
    "#include <tuple>\n",
    "#include <vector>\n",
    "#include <pybind11/pybind11.h>\n",
    "//#include <pybind11/stl.h>\n",
    "#include <pybind11/numpy.h>\n",
    "#include <omp.h>\n",
    "\n",
    "#include \"matrix_class.h\"\n",
    "\n",
    "namespace py = pybind11;\n",
    "\n",
    "std::tuple<double, double, double> work_3a(const int kData_dim,\n",
    "                                           const int kDivisions,\n",
    "                                           py::array_t<int> &py_X0,\n",
    "                                           py::array_t<int> &py_X1,\n",
    "                                           py::array_t<int> &py_X2,\n",
    "                                           const int kN_classes,\n",
    "                                           py::array_t<double> &py_pseudo_counts,\n",
    "                                           py::array_t<int> &py_y) {\n",
    "    \n",
    "    const int kC_Xdim = kDivisions + 1;\n",
    "    const int kC_ydim = kN_classes;\n",
    "    \n",
    "    py::buffer_info py_X0_buf = py_X0.request();\n",
    "    auto *X0 = static_cast<int *>(py_X0_buf.ptr);\n",
    "    py::buffer_info py_X1_buf = py_X1.request();\n",
    "    auto *X1 = static_cast<int *>(py_X1_buf.ptr);\n",
    "    py::buffer_info py_X2_buf = py_X2.request();\n",
    "    auto *X2 = static_cast<int *>(py_X2_buf.ptr);\n",
    "    \n",
    "    py::buffer_info py_y_buf = py_y.request();\n",
    "    auto *y = static_cast<int *>(py_y_buf.ptr);\n",
    "    \n",
    "    py::buffer_info py_pseudo_counts_buf = py_pseudo_counts.request();\n",
    "    auto *pseudo_counts = static_cast<double *>(py_pseudo_counts_buf.ptr);\n",
    "    \n",
    "    Matrix<int> contingency_m(kC_Xdim, kC_Xdim, kC_Xdim, kC_ydim);\n",
    "    Matrix<double> contingency_m_y(kC_Xdim, kC_Xdim, kC_Xdim);\n",
    "    \n",
    "    for (int data_idx = 0; data_idx < kData_dim; data_idx++) {\n",
    "        ++contingency_m(X0[data_idx], X1[data_idx], X2[data_idx], y[data_idx]);\n",
    "    }\n",
    "\n",
    "    double neg_H = 0., neg_H_X0 = 0., neg_H_X1 = 0., neg_H_X2 = 0.;\n",
    "    \n",
    "    #pragma omp parallel\n",
    "    {\n",
    "    \n",
    "    #pragma omp for reduction (+: neg_H, neg_H_X0, neg_H_X1, neg_H_X2)\n",
    "    for (int C_Xidx_i = 0; C_Xidx_i < kC_Xdim; ++C_Xidx_i) {\n",
    "        for (int C_Xidx_j = 0; C_Xidx_j < kC_Xdim; ++C_Xidx_j) {\n",
    "            for (int C_yidx = 0; C_yidx < kC_ydim; ++C_yidx) {\n",
    "                double count_X0 = 0;\n",
    "                double count_X1 = 0;\n",
    "                double count_X2 = 0;\n",
    "                for (int C_Xidx_k = 0; C_Xidx_k < kC_Xdim; C_Xidx_k++) {\n",
    "                    double count_ijk = pseudo_counts[C_yidx] + contingency_m(C_Xidx_i, C_Xidx_j, C_Xidx_k, C_yidx);\n",
    "                    count_X0 += pseudo_counts[C_yidx] + contingency_m(C_Xidx_k, C_Xidx_i, C_Xidx_j, C_yidx);\n",
    "                    count_X1 += pseudo_counts[C_yidx] + contingency_m(C_Xidx_i, C_Xidx_k, C_Xidx_j, C_yidx);\n",
    "                    count_X2 += count_ijk;\n",
    "                    contingency_m_y(C_Xidx_i, C_Xidx_j, C_Xidx_k) += count_ijk;\n",
    "                    neg_H += count_ijk * log2(count_ijk);\n",
    "                }\n",
    "                neg_H_X0 += count_X0 * log2(count_X0);\n",
    "                neg_H_X1 += count_X1 * log2(count_X1);\n",
    "                neg_H_X2 += count_X2 * log2(count_X2);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #pragma omp for reduction (+: neg_H, neg_H_X0, neg_H_X1, neg_H_X2)\n",
    "    for (int C_Xidx_i = 0; C_Xidx_i < kC_Xdim; ++C_Xidx_i) {\n",
    "        for (int C_Xidx_j = 0; C_Xidx_j < kC_Xdim; ++C_Xidx_j) {\n",
    "            double count_X0_y = 0;\n",
    "            double count_X1_y = 0;\n",
    "            double count_X2_y = 0;\n",
    "            for (int C_Xidx_k = 0; C_Xidx_k < kC_Xdim; ++C_Xidx_k) {\n",
    "                double count_y_ijk = contingency_m_y(C_Xidx_i, C_Xidx_j, C_Xidx_k);\n",
    "                neg_H -= count_y_ijk * log2(count_y_ijk);\n",
    "                count_X0_y += contingency_m_y(C_Xidx_k, C_Xidx_i, C_Xidx_j);\n",
    "                count_X1_y += contingency_m_y(C_Xidx_i, C_Xidx_k, C_Xidx_j);\n",
    "                count_X2_y += contingency_m_y(C_Xidx_i, C_Xidx_j, C_Xidx_k);\n",
    "            }\n",
    "            neg_H_X0 -= count_X0_y * log2(count_X0_y);\n",
    "            neg_H_X1 -= count_X1_y * log2(count_X1_y);\n",
    "            neg_H_X2 -= count_X2_y * log2(count_X2_y);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    }\n",
    "    \n",
    "    return std::make_tuple(neg_H - neg_H_X0,\n",
    "                           neg_H - neg_H_X1,\n",
    "                           neg_H - neg_H_X2\n",
    "                          );    \n",
    "}\n",
    "\n",
    "std::tuple<double, double, double> work_3b(const int kData_dim,\n",
    "                                           const int kDivisions,\n",
    "                                           py::array_t<int> &py_X0,\n",
    "                                           py::array_t<int> &py_X1,\n",
    "                                           py::array_t<int> &py_X2,\n",
    "                                           const int kN_classes,\n",
    "                                           py::array_t<double> &py_pseudo_counts,\n",
    "                                           py::array_t<int> &py_y) {\n",
    "    \n",
    "    const int kC_Xdim = kDivisions + 1;\n",
    "    const int kC_ydim = kN_classes;\n",
    "    \n",
    "    py::buffer_info py_X0_buf = py_X0.request();\n",
    "    auto *X0 = static_cast<int *>(py_X0_buf.ptr);\n",
    "    py::buffer_info py_X1_buf = py_X1.request();\n",
    "    auto *X1 = static_cast<int *>(py_X1_buf.ptr);\n",
    "    py::buffer_info py_X2_buf = py_X2.request();\n",
    "    auto *X2 = static_cast<int *>(py_X2_buf.ptr);\n",
    "    \n",
    "    py::buffer_info py_y_buf = py_y.request();\n",
    "    auto *y = static_cast<int *>(py_y_buf.ptr);\n",
    "    \n",
    "    py::buffer_info py_pseudo_counts_buf = py_pseudo_counts.request();\n",
    "    auto *pseudo_counts = static_cast<double *>(py_pseudo_counts_buf.ptr);\n",
    "    \n",
    "    Matrix<int> contingency_m(kC_Xdim, kC_Xdim, kC_Xdim, kC_ydim);\n",
    "    Matrix<double> contingency_m_y(kC_Xdim, kC_Xdim, kC_Xdim);\n",
    "    \n",
    "    Matrix<omp_lock_t> contingency_m_lock(kC_Xdim, kC_Xdim, kC_Xdim, kC_ydim);\n",
    "                                                                                                \n",
    "    for (int C_Xidx_0 = 0; C_Xidx_0 < kC_Xdim; ++C_Xidx_0) {\n",
    "        for (int C_Xidx_1 = 0; C_Xidx_1 < kC_Xdim; ++C_Xidx_1) {\n",
    "            for (int C_Xidx_2 = 0; C_Xidx_2 < kC_Xdim; ++C_Xidx_2) {\n",
    "                for (int C_yidx = 0; C_yidx < kC_ydim; ++C_yidx) {\n",
    "                    omp_init_lock(&contingency_m_lock(C_Xidx_0, C_Xidx_1, C_Xidx_2, C_yidx));\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    double neg_H = 0., neg_H_X0 = 0., neg_H_X1 = 0., neg_H_X2 = 0.;\n",
    "    \n",
    "    #pragma omp parallel\n",
    "    {\n",
    "    \n",
    "    #pragma omp for                                           \n",
    "    for (int data_idx = 0; data_idx < kData_dim; data_idx++) {\n",
    "        omp_set_lock(&contingency_m_lock(X0[data_idx], X1[data_idx], X2[data_idx], y[data_idx]));\n",
    "        ++contingency_m(X0[data_idx], X1[data_idx], X2[data_idx], y[data_idx]);\n",
    "        omp_unset_lock(&contingency_m_lock(X0[data_idx], X1[data_idx], X2[data_idx], y[data_idx]));\n",
    "    }\n",
    "    \n",
    "    #pragma omp for reduction (+: neg_H, neg_H_X0, neg_H_X1, neg_H_X2)\n",
    "    for (int C_Xidx_i = 0; C_Xidx_i < kC_Xdim; ++C_Xidx_i) {\n",
    "        for (int C_Xidx_j = 0; C_Xidx_j < kC_Xdim; ++C_Xidx_j) {\n",
    "            for (int C_yidx = 0; C_yidx < kC_ydim; ++C_yidx) {\n",
    "                double count_X0 = 0;\n",
    "                double count_X1 = 0;\n",
    "                double count_X2 = 0;\n",
    "                for (int C_Xidx_k = 0; C_Xidx_k < kC_Xdim; C_Xidx_k++) {\n",
    "                    double count_ijk = pseudo_counts[C_yidx] + contingency_m(C_Xidx_i, C_Xidx_j, C_Xidx_k, C_yidx);\n",
    "                    count_X0 += pseudo_counts[C_yidx] + contingency_m(C_Xidx_k, C_Xidx_i, C_Xidx_j, C_yidx);\n",
    "                    count_X1 += pseudo_counts[C_yidx] + contingency_m(C_Xidx_i, C_Xidx_k, C_Xidx_j, C_yidx);\n",
    "                    count_X2 += count_ijk;\n",
    "                    contingency_m_y(C_Xidx_i, C_Xidx_j, C_Xidx_k) += count_ijk;\n",
    "                    neg_H += count_ijk * log2(count_ijk);\n",
    "                }\n",
    "                neg_H_X0 += count_X0 * log2(count_X0);\n",
    "                neg_H_X1 += count_X1 * log2(count_X1);\n",
    "                neg_H_X2 += count_X2 * log2(count_X2);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #pragma omp for reduction (+: neg_H, neg_H_X0, neg_H_X1, neg_H_X2)\n",
    "    for (int C_Xidx_i = 0; C_Xidx_i < kC_Xdim; ++C_Xidx_i) {\n",
    "        for (int C_Xidx_j = 0; C_Xidx_j < kC_Xdim; ++C_Xidx_j) {\n",
    "            double count_X0_y = 0;\n",
    "            double count_X1_y = 0;\n",
    "            double count_X2_y = 0;\n",
    "            for (int C_Xidx_k = 0; C_Xidx_k < kC_Xdim; ++C_Xidx_k) {\n",
    "                double count_y_ijk = contingency_m_y(C_Xidx_i, C_Xidx_j, C_Xidx_k);\n",
    "                neg_H -= count_y_ijk * log2(count_y_ijk);\n",
    "                count_X0_y += contingency_m_y(C_Xidx_k, C_Xidx_i, C_Xidx_j);\n",
    "                count_X1_y += contingency_m_y(C_Xidx_i, C_Xidx_k, C_Xidx_j);\n",
    "                count_X2_y += contingency_m_y(C_Xidx_i, C_Xidx_j, C_Xidx_k);\n",
    "            }\n",
    "            neg_H_X0 -= count_X0_y * log2(count_X0_y);\n",
    "            neg_H_X1 -= count_X1_y * log2(count_X1_y);\n",
    "            neg_H_X2 -= count_X2_y * log2(count_X2_y);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    }\n",
    "    \n",
    "    return std::make_tuple(neg_H - neg_H_X0,\n",
    "                           neg_H - neg_H_X1,\n",
    "                           neg_H - neg_H_X2\n",
    "                          );    \n",
    "}\n",
    "\n",
    "std::tuple<double, double, double> work_3c(const int kData_dim,\n",
    "                                           const int kDivisions,\n",
    "                                           py::array_t<int> &py_X0,\n",
    "                                           py::array_t<int> &py_X1,\n",
    "                                           py::array_t<int> &py_X2,\n",
    "                                           const int kN_classes,\n",
    "                                           py::array_t<double> &py_pseudo_counts,\n",
    "                                           py::array_t<int> &py_y) {\n",
    "    \n",
    "    const int kC_Xdim = kDivisions + 1;\n",
    "    const int kC_ydim = kN_classes;\n",
    "    \n",
    "    py::buffer_info py_X0_buf = py_X0.request();\n",
    "    auto *X0 = static_cast<int *>(py_X0_buf.ptr);\n",
    "    py::buffer_info py_X1_buf = py_X1.request();\n",
    "    auto *X1 = static_cast<int *>(py_X1_buf.ptr);\n",
    "    py::buffer_info py_X2_buf = py_X2.request();\n",
    "    auto *X2 = static_cast<int *>(py_X2_buf.ptr);\n",
    "    \n",
    "    py::buffer_info py_y_buf = py_y.request();\n",
    "    auto *y = static_cast<int *>(py_y_buf.ptr);\n",
    "    \n",
    "    py::buffer_info py_pseudo_counts_buf = py_pseudo_counts.request();\n",
    "    auto *pseudo_counts = static_cast<double *>(py_pseudo_counts_buf.ptr);\n",
    "    \n",
    "    Matrix<int> contingency_m(kC_Xdim, kC_Xdim, kC_Xdim, kC_ydim);\n",
    "    Matrix<double> contingency_m_y(kC_Xdim, kC_Xdim, kC_Xdim);                                                                                                \n",
    "\n",
    "\n",
    "    double neg_H = 0., neg_H_X0 = 0., neg_H_X1 = 0., neg_H_X2 = 0.;\n",
    "    \n",
    "    #pragma omp parallel\n",
    "    {\n",
    "    \n",
    "    #pragma omp for                                         \n",
    "    for (int data_idx = 0; data_idx < kData_dim; data_idx++) {\n",
    "        #pragma omp atomic\n",
    "            ++contingency_m(X0[data_idx], X1[data_idx], X2[data_idx], y[data_idx]);\n",
    "    }\n",
    "    \n",
    "    #pragma omp for reduction (+: neg_H, neg_H_X0, neg_H_X1, neg_H_X2)\n",
    "    for (int C_Xidx_i = 0; C_Xidx_i < kC_Xdim; ++C_Xidx_i) {\n",
    "        for (int C_Xidx_j = 0; C_Xidx_j < kC_Xdim; ++C_Xidx_j) {\n",
    "            for (int C_yidx = 0; C_yidx < kC_ydim; ++C_yidx) {\n",
    "                double count_X0 = 0;\n",
    "                double count_X1 = 0;\n",
    "                double count_X2 = 0;\n",
    "                for (int C_Xidx_k = 0; C_Xidx_k < kC_Xdim; C_Xidx_k++) {\n",
    "                    double count_ijk = pseudo_counts[C_yidx] + contingency_m(C_Xidx_i, C_Xidx_j, C_Xidx_k, C_yidx);\n",
    "                    count_X0 += pseudo_counts[C_yidx] + contingency_m(C_Xidx_k, C_Xidx_i, C_Xidx_j, C_yidx);\n",
    "                    count_X1 += pseudo_counts[C_yidx] + contingency_m(C_Xidx_i, C_Xidx_k, C_Xidx_j, C_yidx);\n",
    "                    count_X2 += count_ijk;\n",
    "                    contingency_m_y(C_Xidx_i, C_Xidx_j, C_Xidx_k) += count_ijk;\n",
    "                    neg_H += count_ijk * log2(count_ijk);\n",
    "                }\n",
    "                neg_H_X0 += count_X0 * log2(count_X0);\n",
    "                neg_H_X1 += count_X1 * log2(count_X1);\n",
    "                neg_H_X2 += count_X2 * log2(count_X2);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #pragma omp for reduction (+: neg_H, neg_H_X0, neg_H_X1, neg_H_X2)\n",
    "    for (int C_Xidx_i = 0; C_Xidx_i < kC_Xdim; ++C_Xidx_i) {\n",
    "        for (int C_Xidx_j = 0; C_Xidx_j < kC_Xdim; ++C_Xidx_j) {\n",
    "            double count_X0_y = 0;\n",
    "            double count_X1_y = 0;\n",
    "            double count_X2_y = 0;\n",
    "            for (int C_Xidx_k = 0; C_Xidx_k < kC_Xdim; ++C_Xidx_k) {\n",
    "                double count_y_ijk = contingency_m_y(C_Xidx_i, C_Xidx_j, C_Xidx_k);\n",
    "                neg_H -= count_y_ijk * log2(count_y_ijk);\n",
    "                count_X0_y += contingency_m_y(C_Xidx_k, C_Xidx_i, C_Xidx_j);\n",
    "                count_X1_y += contingency_m_y(C_Xidx_i, C_Xidx_k, C_Xidx_j);\n",
    "                count_X2_y += contingency_m_y(C_Xidx_i, C_Xidx_j, C_Xidx_k);\n",
    "            }\n",
    "            neg_H_X0 -= count_X0_y * log2(count_X0_y);\n",
    "            neg_H_X1 -= count_X1_y * log2(count_X1_y);\n",
    "            neg_H_X2 -= count_X2_y * log2(count_X2_y);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    }\n",
    "    \n",
    "    return std::make_tuple(neg_H - neg_H_X0,\n",
    "                           neg_H - neg_H_X1,\n",
    "                           neg_H - neg_H_X2\n",
    "                          );    \n",
    "}\n",
    "    \n",
    "\n",
    "std::tuple<double, double, double> work_3_old(const int kData_dim,\n",
    "                                              const int kDivisions,\n",
    "                                              py::array_t<int> &py_X0,\n",
    "                                              py::array_t<int> &py_X1,\n",
    "                                              py::array_t<int> &py_X2,\n",
    "                                              const int kN_classes,\n",
    "                                              py::array_t<double> &py_pseudo_counts,\n",
    "                                              py::array_t<int> &py_y) {\n",
    "    \n",
    "    const int kC_Xdim = kDivisions + 1;\n",
    "    const int kC_ydim = kN_classes;\n",
    "    \n",
    "    py::buffer_info py_X0_buf = py_X0.request();\n",
    "    auto *X0 = static_cast<int *>(py_X0_buf.ptr);\n",
    "    py::buffer_info py_X1_buf = py_X1.request();\n",
    "    auto *X1 = static_cast<int *>(py_X1_buf.ptr);\n",
    "    py::buffer_info py_X2_buf = py_X2.request();\n",
    "    auto *X2 = static_cast<int *>(py_X2_buf.ptr);\n",
    "    \n",
    "    py::buffer_info py_y_buf = py_y.request();\n",
    "    auto *y = static_cast<int *>(py_y_buf.ptr);\n",
    "    \n",
    "    py::buffer_info py_pseudo_counts_buf = py_pseudo_counts.request();\n",
    "    auto *pseudo_counts = static_cast<double *>(py_pseudo_counts_buf.ptr);\n",
    "    \n",
    "    int contingency_m[kC_Xdim][kC_Xdim][kC_Xdim][kC_ydim] = {};\n",
    "    double contingency_m_y[kC_Xdim][kC_Xdim][kC_Xdim] = {};\n",
    "\n",
    "    for (int data_idx = 0; data_idx < kData_dim; data_idx++) {\n",
    "        contingency_m[X0[data_idx]][X1[data_idx]][X2[data_idx]][y[data_idx]]++;\n",
    "    }\n",
    "\n",
    "    double neg_H = 0., neg_H_X0 = 0., neg_H_X1 = 0., neg_H_X2 = 0.;\n",
    "    \n",
    "    #pragma omp parallel\n",
    "    {\n",
    "    \n",
    "    #pragma omp for reduction (+: neg_H, neg_H_X0, neg_H_X1, neg_H_X2)\n",
    "    for (int C_Xidx_i = 0; C_Xidx_i < kC_Xdim; C_Xidx_i++) {\n",
    "        for (int C_Xidx_j = 0; C_Xidx_j < kC_Xdim; C_Xidx_j++) {\n",
    "            for (int C_yidx = 0; C_yidx < kC_ydim; C_yidx++) {\n",
    "                double count_X0 = 0;\n",
    "                double count_X1 = 0;\n",
    "                double count_X2 = 0;\n",
    "                for (int C_Xidx_k = 0; C_Xidx_k < kC_Xdim; C_Xidx_k++) {\n",
    "                    double count_ijk = pseudo_counts[C_yidx] + contingency_m[C_Xidx_i][C_Xidx_j][C_Xidx_k][C_yidx];\n",
    "                    count_X0 += pseudo_counts[C_yidx] + contingency_m[C_Xidx_k][C_Xidx_i][C_Xidx_j][C_yidx];\n",
    "                    count_X1 += pseudo_counts[C_yidx] + contingency_m[C_Xidx_i][C_Xidx_k][C_Xidx_j][C_yidx];\n",
    "                    count_X2 += count_ijk;\n",
    "                    contingency_m_y[C_Xidx_i][C_Xidx_j][C_Xidx_k] += count_ijk;\n",
    "                    neg_H += count_ijk * log2(count_ijk);\n",
    "                }\n",
    "                neg_H_X0 += count_X0 * log2(count_X0);\n",
    "                neg_H_X1 += count_X1 * log2(count_X1);\n",
    "                neg_H_X2 += count_X2 * log2(count_X2);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #pragma omp for reduction (+: neg_H, neg_H_X0, neg_H_X1, neg_H_X2)\n",
    "    for (int C_Xidx_i = 0; C_Xidx_i < kC_Xdim; C_Xidx_i++) {\n",
    "        for (int C_Xidx_j = 0; C_Xidx_j < kC_Xdim; C_Xidx_j++) {\n",
    "            double count_X0_y = 0;\n",
    "            double count_X1_y = 0;\n",
    "            double count_X2_y = 0;\n",
    "            for (int C_Xidx_k = 0; C_Xidx_k < kC_Xdim; C_Xidx_k++) {\n",
    "                neg_H -= contingency_m_y[C_Xidx_i][C_Xidx_j][C_Xidx_k] * log2(contingency_m_y[C_Xidx_i][C_Xidx_j][C_Xidx_k]);\n",
    "                count_X0_y += contingency_m_y[C_Xidx_k][C_Xidx_i][C_Xidx_j];\n",
    "                count_X1_y += contingency_m_y[C_Xidx_i][C_Xidx_k][C_Xidx_j];\n",
    "                count_X2_y += contingency_m_y[C_Xidx_i][C_Xidx_j][C_Xidx_k];\n",
    "            }\n",
    "            neg_H_X0 -= count_X0_y * log2(count_X0_y);\n",
    "            neg_H_X1 -= count_X1_y * log2(count_X1_y);\n",
    "            neg_H_X2 -= count_X2_y * log2(count_X2_y);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    }\n",
    "        \n",
    "    return std::make_tuple(neg_H - neg_H_X0,\n",
    "                           neg_H - neg_H_X1,\n",
    "                           neg_H - neg_H_X2\n",
    "                          );\n",
    "}\n",
    "       \n",
    "\n",
    "PYBIND11_MODULE(fast, module) {\n",
    "    module.def(\"work_3a\", &work_3a);\n",
    "    module.def(\"work_3b\", &work_3b);\n",
    "    module.def(\"work_3c\", &work_3c);\n",
    "    module.def(\"work_3_old\", &work_3_old);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cppimport\n",
    "#cppimport.set_quiet(False)\n",
    "\n",
    "fast = cppimport.imp(\"fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Make a data sample: pick `n` last X-columns in the `madelon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "madelon = read_csv(\"madelon.csv\", header=None)\n",
    "madelon.iloc[:,-(n + 2):].to_csv('madelon_tiny.csv', header=False, index=False)\n",
    "madelon_tiny = read_csv(\"madelon_tiny.csv\", dtype = 'float64', header=None)\n",
    "madelon_tiny.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Run the thing synchronously (make it a standalone script for profiling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing march0_n1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile march0_n1.py\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from pandas import read_csv, DataFrame\n",
    "from itertools import product, chain, starmap, combinations, combinations_with_replacement\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "import fast\n",
    "\n",
    "time0 = time()\n",
    "\n",
    "k = 3\n",
    "divisions = 1\n",
    "range_ = 0.00\n",
    "seed = 123\n",
    "\n",
    "# 1. Function definitions\n",
    "\n",
    "def discretize(seq, divisions=divisions, range_=range_, seed=seed):\n",
    "    '''\n",
    "    >>> discretize([3, 4, 1, 8, 13, 8], divisions=4, range_=0, seed=123) = array([1, 1, 0, 2, 3, 2])\n",
    "    where\n",
    "    ranks = [2., 3., 1., 4.5, 6., 4.5]\n",
    "    tresholds = [1.5,  3.,  4.5]\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    ranks = rankdata(seq, method='ordinal') # method='ordinal'/'average' ?\n",
    "\n",
    "    random_blocks = np.cumsum(range_ * (2 * np.random.random(divisions + 1) - 1) + np.ones(divisions + 1))\n",
    "    tresholds = random_blocks[:-1] / random_blocks[-1] * len(seq)\n",
    "    \n",
    "    discrete_seq = np.zeros(len(seq), dtype='int32')\n",
    "    for treshold in tresholds:\n",
    "        discrete_seq[ranks > treshold] += 1\n",
    "    return discrete_seq\n",
    "\n",
    "discretize_vec = np.vectorize(discretize, signature='(n)->(n)', excluded=['divisions', 'range_', 'seed'])\n",
    "\n",
    "# 2. Read the data\n",
    "\n",
    "file = \"madelon_tiny.csv\"\n",
    "input_ = []\n",
    "with open(file) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',',\n",
    "                        quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader:\n",
    "        input_.append(row)\n",
    "        \n",
    "input_ = np.array(input_, dtype='float64').T[:-1]\n",
    "data = np.empty(input_.shape, dtype='int32')\n",
    "data[:-1] = discretize_vec(input_[:-1])\n",
    "data[-1] = input_[-1:].astype('int32')\n",
    "\n",
    "labels, counts = np.unique(data[-1], return_counts=True)\n",
    "n_classes = len(labels)\n",
    "\n",
    "xi = 0.25\n",
    "pseudo_counts = xi * counts / np.min(counts)\n",
    "\n",
    "dim0, dim1 = data[:-1].shape\n",
    "\n",
    "# 3. More function definitions\n",
    "\n",
    "def tuple_generator(k=k, dim0=dim0):\n",
    "    '''\n",
    "    Python-generator.\n",
    "    E.g. output for k=2:\n",
    "    {0,1}, {0,2}, ..., {0, dim0-1}, {1,2}, ..., {1,dim0-1}, ..., {dim0-2, dim0-1}\n",
    "    Go with combinations_with_replacement() to include diagonal tuples like {0, 0}\n",
    "    '''        \n",
    "    return combinations(range(dim0), k)    \n",
    "\n",
    "def neg_H(p):\n",
    "    return p * np.log2(p)\n",
    "\n",
    "def neg_H_cond(matrix):\n",
    "    return np.sum(neg_H(matrix)) - np.sum(neg_H(np.sum(matrix, axis=-1)))\n",
    "\n",
    "def slow_work(indeces):\n",
    "    '''\n",
    "    indeces -> tuple\n",
    "    Work-function.\n",
    "    Output: tuple of Information Gains implicitly corresponding to the indeces\n",
    "    '''\n",
    "    # contingency-matrix: begin with pseudo-counts\n",
    "    contingency_m = np.empty([divisions + 1] * k + [len(labels)], dtype='float64')\n",
    "    for label, pseudo_count in enumerate(pseudo_counts):\n",
    "        contingency_m[..., label] = pseudo_count\n",
    "    \n",
    "    # contingency-matrix: normal counts\n",
    "    for c_index in data[list(indeces) + [-1]].T:\n",
    "        contingency_m[tuple(c_index)] += 1\n",
    "    \n",
    "    results = []\n",
    "    for i in range(len(indeces)):\n",
    "        result = neg_H_cond(contingency_m) - neg_H_cond(np.sum(contingency_m, axis=i))\n",
    "        results.append(result)\n",
    "    return tuple(results)\n",
    "\n",
    "\n",
    "def record(tuple_, IGs, records):\n",
    "    for column, IG in zip(tuple_, IGs):\n",
    "        if column not in records or IG > records[column][0]:\n",
    "            records[column] = (IG, tuple_)\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "for tuple_ in tuple_generator():\n",
    "    #IGs = slow_work(tuple_)\n",
    "    #IGs = fast.work_3a(dim1, divisions, data[tuple_[0]], data[tuple_[1]], data[tuple_[2]], n_classes, pseudo_counts, data[-1])\n",
    "    #IGs = fast.work_3b(dim1, divisions, data[tuple_[0]], data[tuple_[1]], data[tuple_[2]], n_classes, pseudo_counts, data[-1])\n",
    "    #IGs = fast.work_3c(dim1, divisions, data[tuple_[0]], data[tuple_[1]], data[tuple_[2]], n_classes, pseudo_counts, data[-1])\n",
    "    IGs = fast.work_3_old(dim1, divisions, data[tuple_[0]], data[tuple_[1]], data[tuple_[2]], n_classes, pseudo_counts, data[-1])\n",
    "    record(tuple_, IGs, final_results)\n",
    "\n",
    "# result\n",
    "print(\"Finished in\", time() - time0, \"sec.\")\n",
    "\n",
    "with open(\"march0_n1_results.pkl\", \"wb\") as file:\n",
    "    pickle.dump(final_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 0.5817179679870605 sec.\n"
     ]
    }
   ],
   "source": [
    "%run march0_n1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IG_max</th>\n",
       "      <th>tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>160.058</td>\n",
       "      <td>(1, 25, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137.622</td>\n",
       "      <td>(1, 3, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135.697</td>\n",
       "      <td>(1, 25, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>135.19</td>\n",
       "      <td>(1, 5, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.0874</td>\n",
       "      <td>(1, 3, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>49.4945</td>\n",
       "      <td>(5, 22, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16.9881</td>\n",
       "      <td>(12, 27, 29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16.2087</td>\n",
       "      <td>(19, 21, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.8175</td>\n",
       "      <td>(9, 16, 39)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.9336</td>\n",
       "      <td>(9, 16, 39)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IG_max         tuple\n",
       "25  160.058   (1, 25, 37)\n",
       "3   137.622     (1, 3, 5)\n",
       "1   135.697   (1, 25, 43)\n",
       "43   135.19    (1, 5, 43)\n",
       "5   55.0874     (1, 3, 5)\n",
       "22  49.4945   (5, 22, 25)\n",
       "27  16.9881  (12, 27, 29)\n",
       "21  16.2087  (19, 21, 40)\n",
       "16  15.8175   (9, 16, 39)\n",
       "9   14.9336   (9, 16, 39)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "with open(\"march0_n1_results.pkl\", \"rb\") as file:\n",
    "    final_results = pickle.load(file)\n",
    "\n",
    "result_n1_df = pd.DataFrame(final_results).T.rename(columns={0: 'IG_max', 1: 'tuple'})\n",
    "result_n1_df.sort_values('IG_max', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 1.0324957370758057 sec.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m cProfile -o march0_n1.prof march0_n1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  4 10:22:37 2019    march0_n1.prof\n",
      "\n",
      "         501685 function calls (491375 primitive calls) in 1.621 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 3425 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    19600    0.732    0.000    0.732    0.000 {built-in method fast.work_3_old}\n",
      "        1    0.243    0.243    1.623    1.623 march0_n1.py:1(<module>)\n",
      "      539    0.064    0.000    0.064    0.000 {built-in method marshal.loads}\n",
      "    822/1    0.047    0.000    1.623    1.623 {built-in method builtins.exec}\n",
      "    19600    0.041    0.000    0.041    0.000 march0_n1.py:102(record)\n",
      "   126/91    0.040    0.000    0.081    0.001 {built-in method _imp.create_dynamic}\n",
      "1574/1559    0.028    0.000    0.080    0.000 {built-in method builtins.__build_class__}\n",
      "      297    0.022    0.000    0.055    0.000 doccer.py:12(docformat)\n",
      "      870    0.013    0.000    0.013    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
      "       48    0.013    0.000    0.013    0.000 config.py:414(register_option)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7fe54805c4e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('march0_n1.prof')\n",
    "#p.sort_stats('time').print_stats(15)\n",
    "p.strip_dirs().sort_stats('time').print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Make a script that uses mpi4py and run with mpi from bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting march0_mpi.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile march0_mpi.py\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from itertools import product, chain, starmap, combinations, combinations_with_replacement\n",
    "import pickle\n",
    "\n",
    "import fast\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "comm.Barrier()\n",
    "time0 = MPI.Wtime()\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "k = 3\n",
    "window = 5\n",
    "divisions = 1\n",
    "range_ = 0.0\n",
    "seed = 123\n",
    "    \n",
    "\n",
    "# 1. Function definitions\n",
    "\n",
    "def discretize(seq, divisions=divisions, range_=range_, seed=seed):\n",
    "    '''\n",
    "    >>> discretize([3, 4, 1, 8, 13, 8], divisions=4, range_=0, seed=123) = array([1, 1, 0, 2, 3, 2])\n",
    "    where\n",
    "    ranks = [2., 3., 1., 4.5, 6., 4.5]\n",
    "    tresholds = [1.5,  3.,  4.5]\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    ranks = rankdata(seq, method='ordinal') # method='ordinal'/'average' ?\n",
    "    \n",
    "    random_blocks = np.cumsum(range_ * (2 * np.random.random(divisions + 1) - 1) + np.ones(divisions + 1))\n",
    "    tresholds = random_blocks[:-1] / random_blocks[-1] * len(seq)\n",
    "    \n",
    "    discrete_seq = np.zeros(len(seq), dtype='float64')\n",
    "    for treshold in tresholds:\n",
    "        discrete_seq[ranks > treshold] += 1\n",
    "    return discrete_seq\n",
    "\n",
    "discretize_vec = np.vectorize(discretize, signature='(n)->(n)', excluded=['divisions', 'range_', 'seed'])\n",
    "\n",
    "# 2. Read the data (in each rank)\n",
    "\n",
    "file = \"madelon_tiny.csv\"\n",
    "input_ = []\n",
    "with open(file) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',',\n",
    "                        quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader:\n",
    "        input_.append(row)\n",
    "        \n",
    "input_ = np.array(input_, dtype='float64').T[:-1]\n",
    "data = np.empty(input_.shape, dtype='int32')\n",
    "data[:-1] = discretize_vec(input_[:-1])\n",
    "data[-1] = input_[-1:].astype('int32')\n",
    "\n",
    "labels, counts = np.unique(data[-1], return_counts=True)\n",
    "n_classes = len(labels)\n",
    "\n",
    "xi = 0.25\n",
    "pseudo_counts = xi * counts / np.min(counts)\n",
    "\n",
    "dim0, dim1 = data[:-1].shape\n",
    "M = (dim0 - 1) // window + 1\n",
    "border_cols = range( (M-1) * window, dim0)\n",
    "\n",
    "if rank == 0:\n",
    "    print(rank, \"dim0 =\", dim0, \"; dim1 =\", dim1)\n",
    "\n",
    "# 3. More function definitions\n",
    "\n",
    "def tile_generator(k=k, M=M):\n",
    "    '''\n",
    "    Python-generator.\n",
    "    E.g. output for k=2:\n",
    "    {0,0}, {0,1}, ..., {0, M-1}, {1,1}, ..., {1,M-1}, ..., {M-1, M-1}\n",
    "    Go with combinations(range(M), k) to exclude diagonal tuples\n",
    "    '''        \n",
    "    return combinations_with_replacement(range(M), k)    \n",
    "\n",
    "def tuple_generator(tile, window=window, border_cols=border_cols):\n",
    "    '''\n",
    "    Map tile into sequence of k-tuples, i.e. fundamental-tiles,\n",
    "    i.e. elements of the cartesian product of the data-columns\n",
    "    '''\n",
    "    index_counts = {index: tile.count(index) for index in tile}\n",
    "    index_to_cols = lambda index: range(index * window, (index + 1) * window) if index != (M - 1) else border_cols \n",
    "    cols_tile = (combinations(index_to_cols(index), count) for (index, count) in index_counts.items())\n",
    "    return (list(chain.from_iterable(col_indeces)) for col_indeces in product(*cols_tile))\n",
    "\n",
    "def neg_H(p):\n",
    "    return p * np.log2(p)\n",
    "\n",
    "def neg_H_cond(matrix):\n",
    "    return np.sum(neg_H(matrix)) - np.sum(neg_H(np.sum(matrix, axis=-1)))\n",
    "\n",
    "def slow_work(tuple_, divisions=divisions, n_classes=n_classes, pseudo_counts=pseudo_counts):\n",
    "    '''\n",
    "    tuple_ -> list # dammit...\n",
    "    Work-function.\n",
    "    Output: tuple of Information Gains implicitly corresponding to column-indeces in the tuple_\n",
    "    '''\n",
    "    # contingency-matrix: begin with pseudo-counts\n",
    "    contingency_m = np.empty([divisions + 1] * k + [n_classes], dtype='float64')\n",
    "    for label, pseudo_count in enumerate(pseudo_counts):\n",
    "        contingency_m[..., label] = pseudo_count\n",
    "    \n",
    "    # contingency-matrix: normal counts\n",
    "    for c_index in data[tuple_ + [-1]].T:\n",
    "        contingency_m[tuple(c_index)] += 1\n",
    "    \n",
    "    IGs = tuple(neg_H_cond(contingency_m) - neg_H_cond(np.sum(contingency_m, axis=i)) for i in range(len(tuple_)))\n",
    "    return IGs\n",
    "\n",
    "\n",
    "def record_tuple(tuple_, IGs, records):\n",
    "    for column, IG in zip(tuple_, IGs):\n",
    "        if column not in records or IG > records[column][0]:\n",
    "            records[column] = (IG, tuple_)\n",
    "            \n",
    "def record_tile(tile_results, records):\n",
    "    for column, (IG, tuple_) in tile_results.items():\n",
    "        if column not in records or IG > records[column][0]:\n",
    "            records[column] = (IG, tuple_)\n",
    "\n",
    "# 4 Work loop\n",
    "\n",
    "if rank == 0:\n",
    "    final_results = {}\n",
    "    current_assignements = {rank: (0, None) for rank in range(1,size)}\n",
    "    \n",
    "    print(rank, \"entering the for loop\")\n",
    "    status = MPI.Status()\n",
    "    for tile in tile_generator():\n",
    "        tile_results = comm.recv(status=status)\n",
    "        record_tile(tile_results, final_results)\n",
    "        comm.isend(tile, dest=status.source)\n",
    "        job_count = current_assignements[status.source][0]\n",
    "        current_assignements[status.source] = (job_count + 1, tile)\n",
    "        \n",
    "        #print(rank, \"currently:\", current_assignements)\n",
    "    \n",
    "    print(rank, \"Work queue is empty\")\n",
    "    for _ in range(size - 1):\n",
    "        tile_results = comm.recv(status=status)\n",
    "        record_tile(tile_results, final_results)\n",
    "        comm.isend(None, dest=status.source)\n",
    "\n",
    "    # Save the results to a file\n",
    "    with open(\"march0_mpi_results.pkl\", \"wb\") as file:\n",
    "        pickle.dump(final_results, file)\n",
    "\n",
    "    print(rank, \"says goodbye\")\n",
    "    print(rank, \"Elapsed:\", MPI.Wtime() - time0, \"sec\")\n",
    "    \n",
    "else:\n",
    "    comm.send({}, dest=0)\n",
    "    print(rank, \"entering the while loop\")\n",
    "    while True:\n",
    "        tile = comm.recv(source = 0)\n",
    "        try:\n",
    "            tile_results = {}\n",
    "            for tuple_ in tuple_generator(tile):\n",
    "                \n",
    "                #IGs = slow_work(tuple_)\n",
    "                #IGs = fast.work_3a(dim1, divisions, data[tuple_[0]], data[tuple_[1]], data[tuple_[2]], n_classes, pseudo_counts, data[-1])\n",
    "                #IGs = fast.work_3b(dim1, divisions, data[tuple_[0]], data[tuple_[1]], data[tuple_[2]], n_classes, pseudo_counts, data[-1])\n",
    "                #IGs = fast.work_3c(dim1, divisions, data[tuple_[0]], data[tuple_[1]], data[tuple_[2]], n_classes, pseudo_counts, data[-1])\n",
    "                IGs = fast.work_3_old(dim1, divisions, data[tuple_[0]], data[tuple_[1]], data[tuple_[2]], n_classes, pseudo_counts, data[-1])\n",
    "                record_tuple(tuple_, IGs, tile_results)\n",
    "            comm.isend(tile_results, dest=0)\n",
    "        except:\n",
    "            print(rank, \"says goodbye\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dim0 = 50 ; dim1 = 2000\n",
      "1 entering the while loop\n",
      "0 entering the for loop\n",
      "0 Work queue is empty\n",
      "1 says goodbye\n",
      "0 says goodbye\n",
      "0 Elapsed: 0.5571421989880037 sec\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export OMP_NUM_THREADS=2\n",
    "mpirun -n 2 python march0_mpi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IG_max</th>\n",
       "      <th>tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>160.058</td>\n",
       "      <td>[1, 25, 37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137.622</td>\n",
       "      <td>[1, 3, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135.697</td>\n",
       "      <td>[1, 43, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>135.19</td>\n",
       "      <td>[1, 5, 43]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.0874</td>\n",
       "      <td>[1, 3, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>49.4945</td>\n",
       "      <td>[5, 22, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16.9881</td>\n",
       "      <td>[12, 27, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16.2087</td>\n",
       "      <td>[40, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.8175</td>\n",
       "      <td>[9, 16, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.9336</td>\n",
       "      <td>[9, 16, 39]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IG_max         tuple\n",
       "25  160.058   [1, 25, 37]\n",
       "3   137.622     [1, 3, 5]\n",
       "1   135.697   [1, 43, 25]\n",
       "43   135.19    [1, 5, 43]\n",
       "5   55.0874     [1, 3, 5]\n",
       "22  49.4945   [5, 22, 25]\n",
       "27  16.9881  [12, 27, 29]\n",
       "21  16.2087  [40, 19, 21]\n",
       "16  15.8175   [9, 16, 39]\n",
       "9   14.9336   [9, 16, 39]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "with open(\"march0_mpi_results.pkl\", \"rb\") as file:\n",
    "    final_results = pickle.load(file)\n",
    "\n",
    "results_mpi_df = pd.DataFrame(final_results).T.rename(columns={0: 'IG_max', 1: 'tuple'})\n",
    "results_mpi_df.sort_values('IG_max', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
